{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "This template is meant to be a starter for your customized DREEM output data analysis.\n",
    "\n",
    "- To install this library, please check the installation on the [Git repo](https://github.com/yvesmartindestaillades/NAP).\n",
    "- To learn how to use this library, please get through the [tutorial](tutorial.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turner overthrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from os.path import exists, dirname\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from dreem_nap import data_wrangler, data_manip, database, plot, utils\n",
    "from dreem_nap.study import Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data wrangling\n",
    "### Step 1.1: Define your study and some basics about your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                                 all samples\n",
       "description                      Simply all of the valid samples\n",
       "samples        [A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, B1, ...\n",
       "title                                                        NaN\n",
       "conditions     [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...\n",
       "Name: all samples, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your root folder for the database (at the moment, keep Yves)\n",
    "folder = 'Yves'\n",
    "\n",
    "path_to_data = 'data'\n",
    "\n",
    "# Firebase credentials file\n",
    "firebase_credentials_file = f\"{path_to_data}/credentials_firebase.json\"\n",
    "with open(firebase_credentials_file) as file:\n",
    "    firebase_credentials = json.load(file)\n",
    "\n",
    "# Select your study\n",
    "study_name = 'all samples' \n",
    "\n",
    "## Set your base coverage high-pass filter value\n",
    "min_bases_cov = 1000 \n",
    "\n",
    "# Set the resolution for the plots\n",
    "mpl.rcParams['figure.dpi'] = 600 # the highest the resolution, the slowest the plotting\n",
    "mpl.rcParams[\"figure.figsize\"] = [25,7]\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# Depending on the study you select, you'll get a series of samples. You can also create new studies using this dictionary.\n",
    "# Here's an example.\n",
    "studies = data_wrangler.load_studies( f\"{path_to_data}/samples.csv\")\n",
    "\n",
    "study = studies.loc[study_name]\n",
    "study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Process new pickle files and push them to Firebase\n",
    "- Select which samples you want to push to Firebase.\n",
    "To plot automatically arrays of samples, see [tutorial](tutorial.ipynb), section 3.2.\n",
    "- Process samples and push them to Firebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle files to process and to push to Firebase\n",
    "pickles_list = []# study.samples # Can be samples if you want to process the samples from your study\n",
    "\n",
    "pickles = {pickle:  f\"{path_to_data}/DREEM/{pickle}/mutation_histos.p\" for pickle in pickles_list}\n",
    "\n",
    "# Indicate the location of your RNA structure file\n",
    "RNAstructureFile =  f\"{path_to_data}/RNAstructureFile.csv\"\n",
    "\n",
    "# Default location for your local database (JSON file)\n",
    "json_file =  f\"{path_to_data}/db.json\"\n",
    "\n",
    "# If the user gives some new pickles files, push them to the firebase, then pull the entire firebase\n",
    "if len(pickles):\n",
    "    data_wrangler.push_samples_to_firebase(pickles = pickles,\n",
    "                        RNAstructureFile = RNAstructureFile,\n",
    "                        firebase_credentials = firebase_credentials,\n",
    "                        min_bases_cov = min_bases_cov, \n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: Pull the data from the Firebase and clean/reformat it.\n",
    "`df` is used for the analysis. Each of the construct have above 1000 reads for each sample.     \n",
    "`df_full` is used for quality quality analysis. It has all constructs above 1000 valid reads for each sample individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from dict-type JSON file\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymdt/dreem_nap/dreem_nap/data_wrangler.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['samples_covered'] = pd.Series(dtype=int)\n",
      "/home/ymdt/dreem_nap/dreem_nap/data_wrangler.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['samples_covered'].loc[construct[1].index] = construct[1]['full_sequence'].count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 constructs were dropped because deltaG was 'void'\n",
      "66 constructs have more than 1000 reads for each base of their ROI on each sample\n"
     ]
    }
   ],
   "source": [
    "# Pull the firebase\n",
    "#df_database = database.load(study=study, folder=folder)\n",
    "\n",
    "#data_wrangler.dump_dict_json(JSONFileDict=json_file, df=df_database)\n",
    "df_database = data_wrangler.json_load(json_file)\n",
    "\n",
    "# Clean and reformat the dataset\n",
    "df, df_full = data_wrangler.clean_dataset(df_database=df_database,\n",
    "                                             study=study)\n",
    "print(f\"{df.groupby('construct')['samples_covered'].count().count()} constructs have more than {min_bases_cov} reads for each base of their ROI on each sample\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data quality analysis\n",
    "\n",
    "It's always hard to realize that you were analysing noise. Here, we'll get through a series a plot to check the data sanity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of samples and constructs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"samples are: {study.samples}\")\n",
    "print(f\"constructs are: {df.construct.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "`get_roi_info(df=df, sample=sample, construct=construct)` gives information about the Region of Interest (ROI) of a (sample, construct) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = utils.rand_sample_construct(df)\n",
    "\n",
    "utils.get_roi_info(df=df, samp=samp, construct=construct)#.xs((True, '0'),level=('paired','roi_structure_comparison'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sample, construct)-specific base coverage plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = utils.rand_sample_construct(df)\n",
    "plot.base_coverage(df, samp, construct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the base coverage per construct distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.base_coverage_ROI_for_all_constructs(df=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity-check construct-wise base coverage plots\n",
    "Plot randomly picked sequences to check the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.random_9_base_coverage(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the roi part coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "             column=\"cov_bases_roi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the second half coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "                column=\"cov_bases_sec_half\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data analysis\n",
    "In this part, we know that we read good data, and we want to visualize it through different plots.\n",
    "\n",
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plots on this notebook? Not recommended if numerous plots\n",
    "show_plots = True\n",
    "\n",
    "# Constructs used\n",
    "a_few_constructs = df.construct.unique()[:3].tolist()\n",
    "first_construct = df.construct.unique()[0].tolist()\n",
    "constructs_per_name = {\n",
    "    'all_constructs': df.construct.unique().tolist(),\n",
    "    str(a_few_constructs) : a_few_constructs,\n",
    "    str(first_construct): [first_construct]\n",
    "}\n",
    "\n",
    "# Select constructs here\n",
    "constructs_name = str(a_few_constructs)\n",
    "\n",
    "# Define what you will analyse\n",
    "constructs = constructs_per_name[constructs_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big script to run every selected function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis run in this script\n",
    "analysis = {'base_per_base_partition':False,\n",
    "            'base_per_base_sequence': True,\n",
    "            'deltaG': True,\n",
    "            'sample_comparison':False,\n",
    "            'columns_csv': True,\n",
    "            'deltaG_construct': True\n",
    "            }\n",
    "\n",
    "# Write here a script to get your plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation sequence-wise\n",
    "\n",
    "`plot.mutation_rate(df, sample, construct, plot_type, index, normalize)` plots the mutation rate base-wise for a given construct of a given sample as a barplot. \n",
    "Arguments:\n",
    "- `plot_type` :\n",
    "    - `'sequence'` : each bar is colored w.r.t to the base of the original sequence.\n",
    "    - `'partition'` : each bar shows the partition of into which bases this base mutates.\n",
    "- `index`:\n",
    "    - `'index'`: each base is identified with its position number\n",
    "    - `'base'`: each base is identified with its type (A, C, G, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in constructs:\n",
    "    for samp in study.samples:\n",
    "        plot.mutation_rate(df=df,\n",
    "                           sample=samp,\n",
    "                           construct=construct,\n",
    "                           plot_type='sequence',\n",
    "                           index='index')\n",
    "        utils.save_fig(path=f\"data/figs/date/{study}/mut_per_base/sequence/{construct}/\", \n",
    "                    title=f\"base_per_base_sequence_{samp}_{construct}\")\n",
    "        plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeltaG plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in study.samples:\n",
    "    plot.deltaG(df=df, sample=samp)\n",
    "\n",
    "    utils.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "             title=f\"deltaG_{samp}\")\n",
    "\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samples correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [constructs[0]]:\n",
    "        df_global_corr = plot.correlation_n_samples(df, study, construct)\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study}\", \n",
    "                      title=f\"correlation_{study}_{construct}\")\n",
    "        plt.title(f\"Study: {study}\")\n",
    "        plt.close(not show_plots)\n",
    "        print(construct, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = False\n",
    "for study in studies:\n",
    "    samples = study['samples']\n",
    "    for constructs in df.construct.unique():\n",
    "        constructs_name = constructs\n",
    "        df_global_corr = plot.correlation_n_samples(df, samples, constructs)\n",
    "        plt.title(f\"Correlation between samples for study: {study}, constructs: {constructs_name}\")\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study}/{constructs_name}\", \n",
    "                        title=f\"correlation_fit_{study}_{constructs_name}\")\n",
    "        plt.close(not show_plots)\n",
    "\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "            plt.title(f\"{plt_type} of the correlation between samples for study: {study}, constructs: {constructs_name}\")\n",
    "            utils.save_fig(path=f\"data/figs/date/correlation/{study}/{constructs_name}\", \n",
    "                            title=f\"correlation_{plt_type}_{study}_{constructs_name}\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", 'r_value').astype(float)\n",
    "df_global_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plt_type in ['r_value', 'slope']:\n",
    "    pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "    f, ax = plt.subplots(figsize=(28, 10))\n",
    "    sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "    plt.title(plt_type)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                    title=f\"correlation_{plt_type}_{study}_all_constructs\")\n",
    "   # plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = True\n",
    "\n",
    "for study in studies:\n",
    "    samples = study['samples']\n",
    "    df_global_corr = plot.correlation_n_samples(df, samples, constructs)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                    title=f\"correlation_{study}_all_constructs\")\n",
    "    plt.close(not show_plots)\n",
    "\n",
    "    if heat_map:\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax, norm=LogNorm())\n",
    "            utils.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                            title=f\"correlation_{plt_type}_{study}_all_constructs\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = 1\n",
    "for study in studies:\n",
    "    samples = studies[study]['samples']\n",
    "    if study == 'all_samples': continue\n",
    "    plot.correlation_n_samples(df, samples, constructs)\n",
    "    plot.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                title=f\"correlation_{study}_all_constructs\")\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature vs reactivity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def mut_rate_along_study(df:pd.DataFrame, study:Study, figsize=None):\n",
    "    \"\"\"Plot the mean of the mutation rate of the ROI bases, for each sample of the study.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of interest.\n",
    "        samples (list[str]): samples of interest.\n",
    "        study: class containing relevant information about the series of sample that you want to use.\n",
    "    \"\"\"\n",
    "    samples = study.samples\n",
    "    paired, unpaired = np.zeros(len(samples)), np.zeros(len(samples))\n",
    "    for count, samp in enumerate(samples):\n",
    "        for construct in df.construct.unique():\n",
    "            df_roi = data_manip.get_roi_info(df, samp, construct, bases=['A','C'])\n",
    "            paired[count] += df_roi.xs(True, level= 'paired')['mut_rate'].mean()/len( df.construct.unique())\n",
    "            unpaired[count] += df_roi.xs(False, level= 'paired')['mut_rate'].mean()/len( df.construct.unique())\n",
    "\n",
    "\n",
    "    if figsize != None:\n",
    "        plt.figure(figsize=figsize)\n",
    "    else:\n",
    "        plt.figure()\n",
    "    plt.plot(study.conditions, paired, 'r.-')\n",
    "    plt.plot(study.conditions, unpaired, 'b.-')\n",
    "         \n",
    "    for str_model in study.models:\n",
    "        model = eval(str_model)\n",
    "        for data in [paired, unpaired]:\n",
    "            fit = curve_fit(model, study.conditions, data)\n",
    "            plt.plot(study.conditions, fit)\n",
    "\n",
    "\n",
    "    plt.xlabel(f\"{study.title}\")\n",
    "    plt.ylabel('Mean mutation rate for the ROI')\n",
    "    plt.legend(['Paired-predicted bases','Unpaired-predicted bases', 'Fit paired-predicted bases', 'Fit unpaired-predicted bases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in studies.iterrows():\n",
    "    study =  Study().from_dict(study[1].to_dict())\n",
    "    study.models = ['lambda x,a: np.log(x)+a']\n",
    "    plot.mut_rate_along_study(df, study, figsize=(16,8))\n",
    "    utils.save_fig(path=f\"{path_to_data}/figs/date/study_behavior\", \n",
    "                title=f\"{study.name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-wise mutation along a study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [df.construct.unique()[0]]:\n",
    "    for stu in studies.iterrows():\n",
    "        study=Study().from_dict(stu[1].to_dict())\n",
    "        if study.name == 'all samples':\n",
    "            continue\n",
    "        plot.study_base_wise_mut_rate(df=df,\n",
    "                                study=study,\n",
    "                                construct=construct)\n",
    "        utils.save_fig(path= f\"{path_to_data}/figs/date/Base-wise mutation along a study/{study.name}\", \n",
    "                       title=f\"{construct}_{study.name}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save columns to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.columns_to_csv(df=df,\n",
    "                   samples=samples,\n",
    "                   columns=['sample', 'construct','full_sequence','roi_sequence','mut_bases','info_bases'],\n",
    "                   title=f\"seq_and_reactivity_{study}\",\n",
    "                   path='data/figs/date/{study}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save construct vs deltaG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.deltaG_vs_construct_to_csv(df=df,    \n",
    "                                 title=f\"deltaG_vs_construct.csv\", \n",
    "                                 path = f\"data/figs/date/{study}\", \n",
    "                                 samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_roi = data_manip.get_roi_info(df, 'E1', 9572, bases=['A','C'])#.reset_index().set_index(['index','paired'])\n",
    "#df_roi = df_roi['mut_rate'].xs(False, level='paired')\n",
    "#df_roi = df_roi.where(df_roi['base'].isin(['A','C'])).dropna()#.xs(False, level='paired').transpose()\n",
    "df_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "study_base_wise_mut_rate() got an unexpected keyword argument 'scale_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ymdt/dreem_nap/Turner_overthrow.ipynb Cell 52'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ymdt/dreem_nap/Turner_overthrow.ipynb#ch0000052?line=0'>1</a>\u001b[0m plot\u001b[39m.\u001b[39;49mstudy_base_wise_mut_rate(df\u001b[39m=\u001b[39;49mdf,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ymdt/dreem_nap/Turner_overthrow.ipynb#ch0000052?line=1'>2</a>\u001b[0m                         study\u001b[39m=\u001b[39;49mStudy()\u001b[39m.\u001b[39;49mfrom_dict(studies\u001b[39m.\u001b[39;49mloc[\u001b[39m'\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ymdt/dreem_nap/Turner_overthrow.ipynb#ch0000052?line=2'>3</a>\u001b[0m                         construct\u001b[39m=\u001b[39;49m\u001b[39m9572\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ymdt/dreem_nap/Turner_overthrow.ipynb#ch0000052?line=3'>4</a>\u001b[0m                         scale_x\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlog\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ymdt/dreem_nap/Turner_overthrow.ipynb#ch0000052?line=4'>5</a>\u001b[0m                         bases\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[0;31mTypeError\u001b[0m: study_base_wise_mut_rate() got an unexpected keyword argument 'scale_x'"
     ]
    }
   ],
   "source": [
    "\n",
    "plot.study_base_wise_mut_rate(df=df,\n",
    "                        study=Study().from_dict(studies.loc['temperature']),\n",
    "                        construct=9572, \n",
    "                        scale_x='log',\n",
    "                        bases=['A','C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "181a95673db9352066c6745a8c0d18f5d1810e89c791a79e01a67e30706bff6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

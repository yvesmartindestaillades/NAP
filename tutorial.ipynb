{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first use, if dreem isn't installed on your computer, open a terminal and enter the following command lines:\n",
    "```\n",
    "$ cd [YOUR PATH TO THIS NAP REPO]\n",
    "$ cd libs\n",
    "$ git clone https://github.com/jyesselm/dreem\n",
    "```\n",
    "Then import regular libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from os.path import exists\n",
    "import os\n",
    "from nap import *\n",
    "try:\n",
    "    sys.path.append(dirname('libs/dreem/dreem')) \n",
    "except:\n",
    "    \"If dreem isn't installed on your computer, the code won't run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.1: Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources used\n",
    "\n",
    "Here, we will set the username (at the moment, we'll call you Yves, it's a nice name). This is your main folder in the database. Check it by yourself [on the database!](https://console.firebase.google.com/u/0/project/dreem-542b7/database/dreem-542b7-default-rtdb/data)\n",
    "\n",
    "The **tubes** that you chose here will be pulled from the database. Every tube correspond to a physical tube, also known as \"experiment\" during the wet lab part.  \n",
    "\n",
    "The **constructs** are specific RNA sequences. They are referred to by their name, such as 8584 or 9572, and each tube has the same series of constructs.\n",
    "\n",
    "A **study** is a group of tubes that are relevant to be studied together. For example, they are all replicates, or the salt concentration was increased along the tubes, etc.\n",
    "\n",
    "The **pickles** are a dictionary of the tube's names and their respective path+title.\n",
    "\n",
    "Set **switch_study** to True when you use another study for the first time. This will remove your former local json and download a new one from the Firebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT THIS ZONE \n",
    "username = 'Yves'\n",
    "study = 'tutorial'  \n",
    "switch_study = True\n",
    "# END OF EDIT ZONE\n",
    "\n",
    "## Database path\n",
    "json_file = 'data/db.json'\n",
    "\n",
    "## Constants\n",
    "min_bases_cov = 1000 \n",
    "mpl.mcParam['figure.dpi'] = 860 # the highest the resolution, the slowest the plotting\n",
    "\n",
    "tubes_per_study = {   'tutorial':['A6','D6'],\n",
    "                      'replicates':['C5','A4' , 'F4', 'A6', 'A7'],\n",
    "                      'salt': ['A6','B6','C6','D6','E6'], \n",
    "                      'temperature':['D7','E7','F7','G7','H7','A8','B8','C8'], \n",
    "                      'magnesium':['F6', 'G6', 'H6', 'A7', 'B7', 'C7'],\n",
    "                      '60 mM DMS kinestics':['D8', 'E8', 'F8', 'G8', 'H8', 'A9']\n",
    "                      }\n",
    "\n",
    "tubes = tubes_per_study[study]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "![figure](tutorial_pics/firebase_schematics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If changed the data, remove the former dataset\n",
    "if switch_study:\n",
    "    try:\n",
    "        os.remove(json_file)\n",
    "    except:\n",
    "        print('No json file to delete')\n",
    "\n",
    "# If not local copy of firebase, pull the firebase, else, load your copy\n",
    "if not exists(json_file):\n",
    "    if not exists('data'):\n",
    "        os.mkdir('data')\n",
    "    df_rough = data_wrangler.load_data_from_firebase(tubes=tubes, username=username)\n",
    "    data_wrangler.dump_dict_json(JSONFileDict=json_file,\n",
    "                                 df=df_rough)\n",
    "else:\n",
    "    df_rough = data_wrangler.load_dict_json(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is normal, so far, a json file was downloaded as `data/db.json`. Now, we'll extract two dataframes from this file, `df_full` for data quality analysis and `df` for data analysis. Check out the difference below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and reformat the dataset. \n",
    "`df` is used for the analysis. Each of the construct have above 1000 reads for each tube.     \n",
    "`df_full` is used for quality quality analysis. It has all constructs above 1000 valid reads for each tube individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_full = turner_overthrow.clean_dataset(df_rough=df_rough,\n",
    "                                             tubes=tubes, \n",
    "                                             min_bases_cov=min_bases_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.2: Data quality analysis\n",
    "\n",
    "It's always hard to realize that you were analysing noise. Here, we'll get through a series a plot to check the data sanity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the tube's quantity of valid structures (good indicator of the tube's quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.valid_construct_per_tube(df=df_full,\n",
    "                              min_bases_cov=min_bases_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the tube coverage distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.tube_coverage_distribution(df=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the base coverage per construct distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.base_coverage_for_all_constructs(df=df_full, \n",
    "                                      min_bases_cov=min_bases_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity-check construct-wise base coverage plots\n",
    "Plot randomly picked sequences to check the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.random_base_coverage_plot_wise(df=df, \n",
    "                                    min_bases_cov=min_bases_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the var part coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "             column=\"cov_bases_var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the second half coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "                column=\"cov_bases_sec_half\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.3: Your turn to play\n",
    "\n",
    "These plots showed the tutorial study. You want to:\n",
    "- Change the study to another study, such as `'temperature'`, and replot this test routine\n",
    "- Write a new study called `'my_new_study'`, using the tubes `['C1','D5','E6','F7']`, and replot this data sanity test routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Analysis\n",
    "In this part, we know that we read good data, and we want to read it through different plots. Let's get through these plots.\n",
    "\n",
    "So far, we've seen that we analyse our data through tubes and constructs. Plot types will require either a (tube, construct) pair, either a given tube, either a given construct. For example, a deltaG plot is tube-wise, because it shows all of the constructs of a given tube. \n",
    "\n",
    "### Step 2.1: Get the list of tubes and constructs:\n",
    "\n",
    "`tubes` comes from your previous study choice, and is the list of the tubes that you want to use.\n",
    "\n",
    "`df.construct.unique()` gives you the list of constructs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tubes are: {tubes}\")\n",
    "print(f\"constructs are: {df.construct.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Explore the data\n",
    "`utils.get_var_info(df=df, tube=tube, construct=construct)` gives information about the variable part of a (tube, construct) pair.\n",
    "\n",
    "Let's explore the data using the previous explored tubs and constructs lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a (tube, construct) pair\n",
    "tube = tubes[0] \n",
    "construct = df.construct.unique()[0]\n",
    "\n",
    "utils.get_var_info(df=df, tube=tube, construct=construct).xs((True, '0'),level=('paired','var_structure_comparison'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: DeltaG plots\n",
    "Step 2.3.1: Let's start with a first plot, deltaG. DeltaG plots the mutation frequency of the paired bases of the variable part of each construct for a given tube. Give this function a tube and plot it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.deltaG(df=df,\n",
    "            tube= \"EDIT ME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.3.2: How about saving this plot directly to your files? Use the following code to save your plot to your files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube = 'EDIT ME'\n",
    "\n",
    "plot.deltaG(df=df, tube=tube)\n",
    "\n",
    "plot.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "                title=f\"deltaG_{tube}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.3.3: Let's say that you want to save all of your tubes plots. Let's make a loop for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tube in tubes:\n",
    "    plot.deltaG(df=df, tube=tube)\n",
    "\n",
    "    plot.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "                  title=f\"deltaG_{tube}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.3.4: These plots are a bit overwhelming, right? Just close them right after saving them to your files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tube in tubes:\n",
    "    plot.deltaG(df=df, tube=tube)\n",
    "\n",
    "    plot.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "                  title=f\"deltaG_{tube}\")\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's been a long way together! Let's apply our new knowledge to another plot type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4: Mutation sequence-wise\n",
    "\n",
    "`plot.mutation_rate(df, tube, construct, plot_type, index, normalize)` plots the mutation rate base-wise for a given (tube construct) pair as a barplot. \n",
    "Arguments:\n",
    "- `plot_type` :\n",
    "    - `'sequence'` : each bar is colored w.r.t to the base of the original sequence.\n",
    "    - `'partition'` : each bar shows the partition of into which bases this base mutates.\n",
    "- `index`:\n",
    "    - `'index'`: each base is identified with its position number\n",
    "    - `'base'`: each base is identified with its type (A, C, G, T)\n",
    "\n",
    "This plot type takes a (tube, construct) pair as an argument. That's fine, we know how to find our tubes list `tubes` and our construct list `df.construct.unique()`. \n",
    "\n",
    "Step 2.4.1: Let's do this plot:\n",
    "- select a tube and a construct in your lists\n",
    "- select `plot_type` : `'sequence'` and  `index`: `'index'`\n",
    "- make the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mutation_rate(df=df,\n",
    "                tube= \"TO DO\",\n",
    "                construct=\"TO DO\",\n",
    "                plot_type=\"TO DO\",\n",
    "                index=\"TO DO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.4.2: Now, use the following parameters:\n",
    "- keep the same tube and construct\n",
    "- select `plot_type` : `'sequence'` and  `index`: `'base'`\n",
    "- make the plot\n",
    "- what's the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mutation_rate(df=df,\n",
    "                tube= \"TO DO\",\n",
    "                construct=\"TO DO\",\n",
    "                plot_type=\"TO DO\",\n",
    "                index=\"TO DO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.4.3: Let's go for a last round. use the following parameters:\n",
    "- keep the same tube and construct\n",
    "- select `plot_type` : `'partition'` and  `index`: `'base'`\n",
    "- make the plot\n",
    "- what's the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mutation_rate(df=df,\n",
    "                tube= \"TO DO\",\n",
    "                construct=\"TO DO\",\n",
    "                plot_type=\"TO DO\",\n",
    "                index=\"TO DO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.4.4: Generate a lot of plots. \n",
    "- Pick your favorite plot type and paste it in the loop.\n",
    "- Define the list of construct that you want to plot.\n",
    "- Run your code\n",
    "- Check your results in the folder `data/figs/date/{study}/mut_per_base/sequence/{construct}`\n",
    "\n",
    "/!\\ WARNING: it takes a few seconds to generate one plot. If you generate too many plots, like the entire `df.construct.unique()` list for all of the `tubes`, it will take a while (on my computer, it takes ~25 minutes). Select subsets of these lists instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructs = ['TO DO']\n",
    "\n",
    "for tube in tubes:\n",
    "    for construct in constructs:\n",
    "        # PASTE THE CODE FOR YOUR FAVORITE PLOT HERE\n",
    "        plot.save_fig(path=f\"data/figs/date/{study}/mut_per_base/sequence/{construct}/\", \n",
    "                    title=f\"base_per_base_sequence_{tube}_{construct}\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5: Tubes comparison\n",
    "This plot type is construct-wise. It compares the mutation rate of each base of this construct within the tube's list, 2 tubes by 2 tubes. The idea is to see the evolution of the data through the study.\n",
    "\n",
    "Step 2.5.1: select a construct and plot this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.compare_n_tubes(df=df,\n",
    "                     tubes = tubes,\n",
    "                     construct= 'TODO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.5.2: Publiposting\n",
    "- Select mutltiple constructs\n",
    "- Produce multiple plots\n",
    "- Open the corresponding folder and check that it worked fine\n",
    "\n",
    "/!\\ WARNING: it takes a few seconds to generate one plot. If you generate too many plots, like the entire `df.construct.unique()` list, it will take a while (on my computer, it takes ~10 minutes). Select subsets of this list instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructs = ['TO DO']\n",
    "\n",
    "for construct in constructs:\n",
    "        plot.compare_n_tubes(df, tubes, construct)\n",
    "        plot.save_fig(path=f\"data/figs/date/{study}/comparison/\", \n",
    "                      title=f\"comparison_{study}_{construct}\")\n",
    "        plt.close()\n",
    "        print(construct, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.6: Save columns to a csv file\n",
    "\n",
    "It can be useful to save relevant data from your dataset.\n",
    "\n",
    "Step 2.6.1: Save columns to a csv file\n",
    "- Set columns to `['tube', 'construct','full_sequence','var_sequence','mut_bases','info_bases']`\n",
    "- Run the code\n",
    "- Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.columns_to_csv(df=df,\n",
    "                   tubes=tubes,\n",
    "                   columns='TO DO',\n",
    "                   title='about_{study}',\n",
    "                   path='data/figs/date/{study}'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.6.2: Save construct vs deltaG \n",
    "\n",
    "- Run the code\n",
    "- Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.deltaG_vs_construct_to_csv(df=df, title=f\"deltaG_vs_construct.csv\", path = f\"data/figs/date\", tubes=tubes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Advanced data management\n",
    "\n",
    "In this part, we will learn how to:\n",
    "- Process pickle files, the output of DREEM. \n",
    "- Push to the database using your own username.\n",
    "\n",
    "/!\\ One pickle file corresponds to one tube of the wet lab experimentation.\n",
    "\n",
    "\n",
    "### Step 3.1 Process pickle files\n",
    "Step 3.1.1: Get a sample dataset (pickles + additional content)\n",
    "\n",
    "- Download it from [this link](https://drive.google.com/drive/folders/1sf7ZkF_TZOjU9MWjm9aB9nqxBTGnxC_d?usp=sharing).\n",
    "- Store the pickle files under `'data/FULLSET/[tube name]/mutation_histos.p'`.\n",
    "- Store the RNAstructure file under `'data/delta_g_plus_bracket_q1.csv'`.\n",
    "- The pickle files you want to process are ['A6','D6']. It corresponds to your tubes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes = ['A6','D6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3.1.2: Generate pickles dictionary\n",
    "`pickles` is a dictionary that has the tubes names as keys and their respective path as values. We use `pickles` to load the pickle files from your computer.\n",
    "\n",
    "To create `pickles`, we use the following function:\n",
    "\n",
    "```\n",
    "pickles = data_wrangler.generate_pickles()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickles = data_wrangler.generate_pickles(path_to_data='data/FULLSET',\n",
    "                                         pickle_list= tubes)\n",
    "print(pickles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Step: Play with data_wrangler.generate_pickles()\n",
    "If you're using a series of repetitive tubes, such that for example ['A1','A2','A3','B1','B2','B3'], you may want to automatize this. \n",
    "\n",
    "Then, you can use additional arguments for data_wrangler.generate_pickles():\n",
    "- `letters_boundaries`: the first and last letters of your tubes set (for example, ['A','D']).\n",
    "- `numbers_boundaries`: the first and last numbers of your tubes set (for example, [1, 3]).\n",
    "- `remove_pickles`: tubes names that are in the set generated by (letters_boundaries, numbers_boundaries), but that you don't want (for example, ['A2','C3'])\n",
    "\n",
    "Exercice bonus:\n",
    "- generate the following pickles list using the previous functions:\n",
    "``` \n",
    "['A1',     'A3','A4','A5','A6',\n",
    "      'B2','B3','B4','B5','B6',\n",
    " 'C1','C2','C3','C4','C5','C6',\n",
    " 'VERY_LONG_NAME_1','VERY_LONG_NAME_2']\n",
    "                                        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_wrangler.generate_pickles(path_to_data='data/FULLSET',\n",
    "                            pickles_list= ['TODO'],\n",
    "                            letters_boundaries =  ['TODO','TODO'],\n",
    "                            number_boundaries=  ['TODO','TODO'],\n",
    "                            remove_pickles= ['TODO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1.3: Push pickles to Firebase\n",
    "Firebase is a database service provided by Google.\n",
    "\n",
    "\n",
    "`data_wrangler.push_pickles_to_firebase()` does the following operations:\n",
    "- loads additional content (typically, the output of RNAstructure)\n",
    "- for each pickle file:\n",
    "    - unpacks and reformat pickle files.\n",
    "    - merges it with additional content (a sequence-wise security check is performed).\n",
    "    - filters out every construct for which the worst base coverage in the region of interest is below `min_bases_cov`. \n",
    "    - pushes the result to Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'CHANGE YOUR USERNAME HERE'\n",
    "RNAstructureFile = 'data/RNAstructureFile.csv'\n",
    "\n",
    "data_wrangler.push_pickles_to_firebase(pickles = pickles,\n",
    "                                        RNAstructureFile = RNAstructureFile,\n",
    "                                        min_bases_cov = min_bases_cov, \n",
    "                                        username = username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### About usernames\n",
    "\n",
    "Your username corresponds to a folder at the database's root. It is useful to create different databases. This is very useful to separate:\n",
    "-  users\n",
    "- projects\n",
    "- versions \n",
    "-  filtering types of the pickle files (such as different values of `min_bases_cov`)\n",
    "\n",
    "A username can contain `/`, to make hierarchical folders. For example, if you create \n",
    "- `Animal/Dog`\n",
    "- `Animal/Cat`\n",
    "- `Animal/Englishman`\n",
    "\n",
    "You'll get:\n",
    "- `Animal`\n",
    "    - `Dog`\n",
    "    - `Cat`\n",
    "    - `Englishman`\n",
    "\n",
    "/!\\ If a username is already used, THIS WILL OVERWRITE THE PREVIOUS DATA. So be careful in your namings :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1.4: Pull from Firebase\n",
    "\n",
    "You made it so far, good job! Now, pull your new dataset and play with it!\n",
    "\n",
    "Exercice 3.1.4:\n",
    "- Pull from the Firebase your data\n",
    "- Get through the data sanity analysis to check that you've done a good job :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove your former dataset\n",
    "try:\n",
    "    os.remove(json_file)\n",
    "except:\n",
    "    print('No json file to delete')\n",
    "\n",
    "# Pull from the firebase\n",
    "df_rough = data_wrangler.load_data_from_firebase(tubes=tubes, username=username)\n",
    "data_wrangler.dump_dict_json(JSONFileDict=json_file,\n",
    "                             df=df_rough)\n",
    "\n",
    "# Clean the data\n",
    "df, df_full = turner_overthrow.clean_dataset(df_rough=df_rough,\n",
    "                                             tubes=tubes, \n",
    "                                             min_bases_cov=min_bases_cov)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "181a95673db9352066c6745a8c0d18f5d1810e89c791a79e01a67e30706bff6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

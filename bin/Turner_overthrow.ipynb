{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "This template is meant to be a starter for your customized DREEM output data analysis.\n",
    "\n",
    "- To install this library, please check the installation on the [Git repo](https://github.com/yvesmartindestaillades/NAP).\n",
    "- To learn how to use this library, please get through the [tutorial](tutorial.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turner overthrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm\n",
    "from os.path import exists, dirname\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from dreem_nap import data_wrangler, data_manip, database, plot, utils\n",
    "from dreem_nap.study import Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data wrangling\n",
    "### Step 1.1: Define your study and some basics about your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your root folder for the database (at the moment, keep Yves)\n",
    "folder = 'Yves'\n",
    "\n",
    "path_to_data = '../data'\n",
    "\n",
    "# Pull the firebase\n",
    "# Firebase credentials file\n",
    "firebase_credentials_file = f\"{path_to_data}/credentials_firebase.json\"\n",
    "with open(firebase_credentials_file) as file:\n",
    "    firebase_credentials = json.load(file)\n",
    "database.connect(firebase_credentials)\n",
    "\n",
    "# Select your study\n",
    "study_name = 'all samples' \n",
    "\n",
    "## Set your base coverage high-pass filter value\n",
    "min_bases_cov = 1000 \n",
    "\n",
    "# Set the resolution for the plots\n",
    "mpl.rcParams['figure.dpi'] = 600 # the highest the resolution, the slowest the plotting\n",
    "mpl.rcParams[\"figure.figsize\"] = [25,7]\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# Depending on the study you select, you'll get a series of samples. You can also create new studies using this dictionary.\n",
    "# Here's an example.\n",
    "studies = data_wrangler.load_studies( f\"{path_to_data}/samples.csv\")\n",
    "\n",
    "print(f\"Here are the available studies: {studies}\")\n",
    "study = studies.loc[study_name]  #chose your study \n",
    "\n",
    "print(f\"Here is your study {study}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Process new pickle files and push them to Firebase\n",
    "- Select which samples you want to push to Firebase.\n",
    "To plot automatically arrays of samples, see [tutorial](tutorial.ipynb), section 3.2.\n",
    "- Process samples and push them to Firebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle files to process and to push to Firebase\n",
    "pickles_list = []# study.samples # Can be samples if you want to process the samples from your study\n",
    "\n",
    "pickles = {pickle:  f\"{path_to_data}/DREEM/{pickle}/mutation_histos.p\" for pickle in pickles_list}\n",
    "\n",
    "# Indicate the location of your RNA structure file\n",
    "RNAstructureFile =  f\"{path_to_data}/RNAstructureFile.csv\"\n",
    "\n",
    "# Default location for your local database (JSON file)\n",
    "json_file =  f\"{path_to_data}/db.json\"\n",
    "\n",
    "# If the user gives some new pickles files, push them to the firebase, then pull the entire firebase\n",
    "if len(pickles):\n",
    "    data_wrangler.push_samples_to_firebase(pickles = pickles,\n",
    "                        RNAstructureFile = RNAstructureFile,\n",
    "                        firebase_credentials = firebase_credentials,\n",
    "                        min_bases_cov = min_bases_cov, \n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: Pull the data from the Firebase and clean/reformat it.\n",
    "`df` is used for the analysis. Each of the construct have above 1000 reads for each sample.     \n",
    "`df_full` is used for quality quality analysis. It has all construct above 1000 valid reads for each sample individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_database = database.load(study=study, folder=folder)\n",
    "\n",
    "#data_wrangler.dump_dict_json(JSONFileDict=json_file, df=df_database)\n",
    "#df_database = data_wrangler.json_load(json_file)\n",
    "\n",
    "# Clean and reformat the dataset\n",
    "df, df_full = data_wrangler.clean_dataset(df_database=df_database,\n",
    "                                             study=study)\n",
    "print(f\"{df.groupby('construct')['samples_covered'].count().count()} constructs have more than {min_bases_cov} reads for each base of their ROI on each sample\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data quality analysis\n",
    "\n",
    "It's always hard to realize that you were analysing noise. Here, we'll get through a series a plot to check the data sanity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of samples and constructs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"samples are: {study.samples}\")\n",
    "print(f\"constructs are: {df.construct.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "`data_manip.get_roi_info()` gives information about the Region of Interest (ROI) of a (sample, construct) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = data_manip.rand_sample_construct(df)\n",
    "\n",
    "data_manip.get_roi_info(df=df,\n",
    "                        samp='D7',\n",
    "                        construct= 381,\n",
    "                        bases= ['A','G','T', 'C'], #bases you want \n",
    "                        structure='full', # which structure prediction, 'full' or 'roi' \n",
    "                        overlay=(10, 5) # extend/shrink the roi, default is 0\n",
    "                       # roi_index= [80, 110]\n",
    "                        )#.xs((True, '0'),level=('paired','roi_structure_comparison'))    #additional filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sample, construct)-specific base coverage plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = data_manip.rand_sample_construct(df)\n",
    "plot.base_coverage(df, samp, construct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the base coverage per construct distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.base_coverage_ROI_for_all_constructs(df=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity-check construct-wise base coverage plots\n",
    "Plot randomly picked sequences to check the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.random_9_base_coverage(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the roi part coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "             column=\"cov_bases_roi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the second half coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "                column=\"cov_bases_sec_half\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data analysis\n",
    "In this part, we know that we read good data, and we want to visualize it through different plots.\n",
    "\n",
    "### Analysis parameters\n",
    "\n",
    "Define a limited amount of constructs if that's useful to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plots on this notebook? Not recommended if numerous plots\n",
    "show_plots = True\n",
    "\n",
    "# Constructs used\n",
    "a_few_constructs = df.construct.unique()[:3].tolist()\n",
    "first_construct = df.construct.unique()[0].tolist()\n",
    "constructs_per_name = {\n",
    "    'all_construct': df.construct.unique().tolist(),\n",
    "    str(a_few_constructs) : a_few_constructs,\n",
    "    str(first_construct): [first_construct]\n",
    "}\n",
    "\n",
    "# Select constructs here\n",
    "constructs_name = str(a_few_constructs)\n",
    "\n",
    "# Define what you will analyse\n",
    "constructs = constructs_per_name[constructs_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of mutation (sample-construct)\n",
    "\n",
    "`plot.mut_histogam(df, sample, construct, plot_type, index, normalize)` plots the mutation rate base-wise for a given construct of a given sample as a barplot. \n",
    "Arguments:\n",
    "- `plot_type` :\n",
    "    - `'sequence'` : each bar is colored w.r.t to the base of the original sequence.\n",
    "    - `'partition'` : each bar shows the partition of into which bases this base mutates.\n",
    "- `index`:\n",
    "    - `'index'`: each base is identified with its position number\n",
    "    - `'base'`: each base is identified with its type (A, C, G, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructs = constructs # Define this beforehand\n",
    "\n",
    "for construct in constructs:\n",
    "    for samp in study.samples:\n",
    "        plot.mut_histogram(df=df,\n",
    "                           samp=samp,\n",
    "                           construct=construct,\n",
    "                           plot_type='index') # Sequence (show the base and their index) or partition (show what the base mutates to)\n",
    "        utils.save_fig(path=f\"data/figs/date/{study.name}/mut_per_base/sequence/{construct}/\", \n",
    "                    title=f\"base_per_base_sequence_{samp}_{construct}\")\n",
    "        plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeltaG plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in study.samples:\n",
    "    plot.deltaG(df=df, sample=samp)\n",
    "\n",
    "    utils.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "             title=f\"deltaG_{samp}\")\n",
    "\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples correlation\n",
    "Only plot the correlation construct-by-construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [constructs[0]]:\n",
    "        df_global_corr = plot.correlation_n_samples(df, study, [construct])\n",
    "        plt.title(f\"Study: {study.name}\")\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study.name}\", \n",
    "                      title=f\"correlation_{study.name}_{construct}\")\n",
    "        plt.close(not show_plots)\n",
    "        print(construct, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the R value + heatmap of the slope for the previous correlation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plt_type in ['r_value', 'slope']:\n",
    "    pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "    f, ax = plt.subplots(figsize=(28, 10))\n",
    "    sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "    plt.title(plt_type)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study.name}\", \n",
    "                    title=f\"correlation_{plt_type}_{study.name}_all_constructs\")\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the correlation + heatmap of the R value + heatmap of the slope construct by construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = False\n",
    "for _, study in studies:\n",
    "    samples = study.samples\n",
    "    for construct in df.construct.unique():\n",
    "        construct_name = construct\n",
    "        df_global_corr = plot.correlation_n_samples(df, study, construct)\n",
    "        plt.title(f\"Correlation between samples for study: {study.name}, constructs: {construct_name}\")\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study.name}/{construct_name}\", \n",
    "                        title=f\"correlation_fit_{study.name}_{construct_name}\")\n",
    "        plt.close(not show_plots)\n",
    "\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "            plt.title(f\"{plt_type} of the correlation between samples for study: {study.name}, construct: {construct_name}\")\n",
    "            utils.save_fig(path=f\"data/figs/date/correlation/{study.name}/{construct_name}\", \n",
    "                            title=f\"correlation_{plt_type}_{study.name}_{construct_name}\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the correlation + heatmap of the R value + heatmap of the slope for a bunch of constructs altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = True\n",
    "\n",
    "constructs = constructs # this has to be defined somewhere\n",
    "\n",
    "for _, study in studies.iterrows():\n",
    "    df_global_corr = plot.correlation_n_samples(df, study, constructs)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study.name}\", \n",
    "                    title=f\"correlation_{study.name}_all_constructs\")\n",
    "    plt.close(not show_plots)\n",
    "\n",
    "    if heat_map:\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax, norm=LogNorm())\n",
    "            utils.save_fig(path=f\"data/figs/date/global_correlation/{study.name}\", \n",
    "                            title=f\"correlation_{plt_type}_{study.name}_all_constructs\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature vs reactivity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.study_sample(df, study, scale_x='log',structure='full', overlay=5, figsize=(16,8))\n",
    "utils.save_fig(path=f\"{path_to_data}/figs/date/study_behavior\", \n",
    "            title=f\"{study.name}.png\")\n",
    "plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _, study in studies.iterrows():\n",
    "    study =  Study().from_dict(study.to_dict())\n",
    "    study.models = ['lambda x,a: np.log(x)+a']\n",
    "    plot.study_sample(df, study, scale_x='log',structure='full', overlay=5, figsize=(16,8))\n",
    "    utils.save_fig(path=f\"{path_to_data}/figs/date/study_behavior\", \n",
    "                title=f\"{study.name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-wise mutation along a study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [df.construct.unique()[0]]:\n",
    "    for stu in studies.iterrows():\n",
    "        study=Study().from_dict(stu[1].to_dict())\n",
    "        if study.name == 'all samples':\n",
    "            continue\n",
    "        plot.study_base(df=df,\n",
    "                study=Study().from_dict(studies.loc['temperature']),\n",
    "                construct=9572, \n",
    "                scale_x='log', # can be log or lin\n",
    "                bases=['A','C'],  # bsaes you want in A, C, G, T\n",
    "                structure='full', # sequence for structure prediction. full or roi. \n",
    "                #overlay = 10,  # expand/shrink the roi. Can't expand roi if structure = 'roi'\n",
    "                base_index=list(range(40,120))) # select your favorite bases. Can't expand roi if structure = 'roi' \n",
    "                \n",
    "        utils.save_fig(path= f\"{path_to_data}/figs/date/Base-wise mutation along a study/{study.name}\", \n",
    "                       title=f\"{construct}_{study.name}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save columns to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manip.columns_to_csv(df=df,\n",
    "                   samples=samples,\n",
    "                   columns=['sample', 'construct','full_sequence','roi_sequence','mut_bases','info_bases'],\n",
    "                   title=f\"seq_and_reactivity_{study}\",\n",
    "                   path='data/figs/date/{study}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save construct vs deltaG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manip.deltaG_vs_construct_to_csv(df=df,    \n",
    "                                 title=f\"deltaG_vs_construct.csv\", \n",
    "                                 path = f\"data/figs/date/{study}\", \n",
    "                                 samples=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "181a95673db9352066c6745a8c0d18f5d1810e89c791a79e01a67e30706bff6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

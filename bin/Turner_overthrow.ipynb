{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "This template is meant to be a starter for your customized DREEM output data analysis.\n",
    "\n",
    "- To install this library, please check the installation on the [Git repo](https://github.com/yvesmartindestaillades/NAP).\n",
    "- To learn how to use this library, please get through the [tutorial](tutorial.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turner overthrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from os.path import exists, dirname\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from dreem_nap import data_wrangler, database, plot, utils\n",
    "from dreem_nap.study import Study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dreem_nap import data_wrangler\n",
    "import json\n",
    "\n",
    "## DREEM\n",
    "# List the files that you want to process and create your pickles dict\n",
    "samples_list = ['A1', 'A2','B3']\n",
    "pickles = {sample: f\"data/DREEM/{sample}/mutation_histos.p\" for sample in samples_list}\n",
    "\n",
    "## RNA-STRUCTURE\n",
    "# Indicate where is your RNAstructure file\n",
    "RNAstructureFile = 'data/RNAstructureFile.csv'\n",
    "\n",
    "## DATA-WRANGLER\n",
    "# Define what is the min base coverage values that you tolerate\n",
    "min_bases_cov = 1000\n",
    "\n",
    "## DATABASE\n",
    "# Select your root folder for the database \n",
    "folder = 'my_project_1/tutorial'\n",
    "\n",
    "# Load Firebase credentials file \n",
    "firebase_credentials_file = 'data/credentials_firebase.json'\n",
    "with open(firebase_credentials_file) as file:\n",
    "    firebase_credentials = json.load(file)\n",
    "\n",
    "## PROCESS DATA\n",
    "# Process your pickles files and push them to Firebase!\n",
    "data_wrangler.push_samples_to_firebase(pickles = pickles,\n",
    "                    RNAstructureFile = RNAstructureFile,\n",
    "                    firebase_credentials = firebase_credentials,\n",
    "                    min_bases_cov = min_bases_cov, \n",
    "                    folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data wrangling\n",
    "### Step 1.1: Define your study and some basics about your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                        magnesium\n",
       "description               Change the Mg concentration\n",
       "samples                      [F6, G6, H6, A7, B7, C7]\n",
       "conditions_unit                                    mM\n",
       "conditions         [0.0, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
       "Name: magnesium, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set your root folder for the database (at the moment, keep Yves)\n",
    "folder = 'Yves'\n",
    "\n",
    "# Firebase credentials file\n",
    "firebase_credentials_file = '../data/credentials_firebase.json'\n",
    "with open(firebase_credentials_file) as file:\n",
    "    firebase_credentials = json.load(file)\n",
    "\n",
    "# Select your study\n",
    "study_name = 'magnesium' \n",
    "\n",
    "## Set your base coverage high-pass filter value\n",
    "min_bases_cov = 1000 \n",
    "\n",
    "# Set the resolution for the plots\n",
    "mpl.rcParams['figure.dpi'] = 600 # the highest the resolution, the slowest the plotting\n",
    "mpl.rcParams[\"figure.figsize\"] = [25,7]\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# Depending on the study you select, you'll get a series of samples. You can also create new studies using this dictionary.\n",
    "# Here's an example.\n",
    "studies = data_wrangler.load_studies('../data/samples.csv')\n",
    "\n",
    "study = studies.loc[study_name]\n",
    "study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Process new pickle files and push them to Firebase\n",
    "- Select which samples you want to push to Firebase.\n",
    "To plot automatically arrays of samples, see [tutorial](tutorial.ipynb), section 3.2.\n",
    "- Process samples and push them to Firebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle files to process and to push to Firebase\n",
    "pickles_list = []# study.samples # Can be samples if you want to process the samples from your study\n",
    "\n",
    "pickles = {pickle: f\"../data/DREEM/{pickle}/mutation_histos.p\" for pickle in pickles_list}\n",
    "\n",
    "# Indicate the location of your RNA structure file\n",
    "RNAstructureFile = '../data/RNAstructureFile.csv'\n",
    "\n",
    "# Default location for your local database (JSON file)\n",
    "json_file = '../data/db.json'\n",
    "\n",
    "# If the user gives some new pickles files, push them to the firebase, then pull the entire firebase\n",
    "if len(pickles):\n",
    "    data_wrangler.push_samples_to_firebase(pickles = pickles,\n",
    "                        RNAstructureFile = RNAstructureFile,\n",
    "                        firebase_credentials = firebase_credentials,\n",
    "                        min_bases_cov = min_bases_cov, \n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: Pull the data from the Firebase and clean/reformat it.\n",
    "`df` is used for the analysis. Each of the construct have above 1000 reads for each sample.     \n",
    "`df_full` is used for quality quality analysis. It has all constructs above 1000 valid reads for each sample individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from dict-type JSON file\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymdt/anaconda3/lib/python3.9/site-packages/dreem_nap/data_wrangler.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['samples_covered'] = pd.Series(dtype=int)\n",
      "/home/ymdt/anaconda3/lib/python3.9/site-packages/dreem_nap/data_wrangler.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['samples_covered'].loc[construct[1].index] = construct[1]['full_sequence'].count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 constructs were dropped because deltaG was 'void'\n",
      "115 constructs have more than 1000 reads for each base of their ROI on each sample\n"
     ]
    }
   ],
   "source": [
    "# Pull the firebase\n",
    "#df_database = database.load(study=study, folder=folder)\n",
    "\n",
    "#data_wrangler.dump_dict_json(JSONFileDict=json_file, df=df_database)\n",
    "df_database = data_wrangler.json_load(json_file)\n",
    "\n",
    "# Clean and reformat the dataset\n",
    "df, df_full = data_wrangler.clean_dataset(df_database=df_database,\n",
    "                                             study=study)\n",
    "print(f\"{df.groupby('construct')['samples_covered'].count().count()} constructs have more than {min_bases_cov} reads for each base of their ROI on each sample\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "samp                                                                       A7\n",
       "construct                                                                 108\n",
       "cov_bases                   [0.0, 2906.0, 2896.0, 2876.0, 2909.0, 2825.0, ...\n",
       "cov_bases_roi                                                            2341\n",
       "cov_bases_sec_half                                                        276\n",
       "data_type                                                                 DMS\n",
       "del_bases                   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, ...\n",
       "end                                                                       170\n",
       "flank                                                                 flank_1\n",
       "full_deltaG                                                             -20.3\n",
       "full_sequence               GACGTTCCTGGATCCTCTATAAGATAACTTTTTCTCTTCCTCTTTC...\n",
       "full_structure              .((((....(((........(((....))).......))).........\n",
       "info_bases                  [0.0, 2937.0, 2937.0, 2937.0, 2938.0, 2938.0, ...\n",
       "ins_bases                   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "mod_bases_A                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "mod_bases_C                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "mod_bases_G                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "mod_bases_T                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "mut_bases                   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...\n",
       "num_aligned                                                              3060\n",
       "num_of_mutations            [778, 820, 814, 411, 135, 57, 31, 8, 5, 0, 1, ...\n",
       "num_reads                                                                4587\n",
       "roi_deltaG                                                               -9.4\n",
       "roi_end_index                                                             103\n",
       "roi_sequence                                          GCACAUGACAAUCAUGCAUGUGC\n",
       "roi_start_index                                                            80\n",
       "roi_structure_comparison                              00000000000000000000000\n",
       "skips_low_mapq                                                           1526\n",
       "skips_short_read                                                            0\n",
       "skips_too_many_muts                                                         1\n",
       "start                                                                       1\n",
       "sub-library                                         MS2 canonical bp variants\n",
       "samples_covered                                                             6\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data quality analysis\n",
    "\n",
    "It's always hard to realize that you were analysing noise. Here, we'll get through a series a plot to check the data sanity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of samples and constructs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"samples are: {study.samples}\")\n",
    "print(f\"constructs are: {df.construct.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "`get_roi_info(df=df, sample=sample, construct=construct)` gives information about the Region of Interest (ROI) of a (sample, construct) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = utils.rand_sample_construct(df)\n",
    "\n",
    "utils.get_roi_info(df=df, samp=samp, construct=construct)#.xs((True, '0'),level=('paired','roi_structure_comparison'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sample, construct)-specific base coverage plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = utils.rand_sample_construct(df)\n",
    "plot.base_coverage(df, samp, construct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the base coverage per construct distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.base_coverage_ROI_for_all_constructs(df=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity-check construct-wise base coverage plots\n",
    "Plot randomly picked sequences to check the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.random_9_base_coverage(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the roi part coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "             column=\"cov_bases_roi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the second half coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "                column=\"cov_bases_sec_half\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data analysis\n",
    "In this part, we know that we read good data, and we want to visualize it through different plots.\n",
    "\n",
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plots on this notebook? Not recommended if numerous plots\n",
    "show_plots = True\n",
    "\n",
    "# Constructs used\n",
    "a_few_constructs = df.construct.unique()[:3].tolist()\n",
    "first_construct = df.construct.unique()[0].tolist()\n",
    "constructs_per_name = {\n",
    "    'all_constructs': df.construct.unique().tolist(),\n",
    "    str(a_few_constructs) : a_few_constructs,\n",
    "    str(first_construct): [first_construct]\n",
    "}\n",
    "\n",
    "# Select constructs here\n",
    "constructs_name = str(a_few_constructs)\n",
    "\n",
    "# Define what you will analyse\n",
    "constructs = constructs_per_name[constructs_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big script to run every selected function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis run in this script\n",
    "analysis = {'base_per_base_partition':False,\n",
    "            'base_per_base_sequence': True,\n",
    "            'deltaG': True,\n",
    "            'sample_comparison':False,\n",
    "            'columns_csv': True,\n",
    "            'deltaG_construct': True\n",
    "            }\n",
    "\n",
    "# Write here a script to get your plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation sequence-wise\n",
    "\n",
    "`plot.mutation_rate(df, sample, construct, plot_type, index, normalize)` plots the mutation rate base-wise for a given construct of a given sample as a barplot. \n",
    "Arguments:\n",
    "- `plot_type` :\n",
    "    - `'sequence'` : each bar is colored w.r.t to the base of the original sequence.\n",
    "    - `'partition'` : each bar shows the partition of into which bases this base mutates.\n",
    "- `index`:\n",
    "    - `'index'`: each base is identified with its position number\n",
    "    - `'base'`: each base is identified with its type (A, C, G, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in constructs:\n",
    "    for samp in study.samples:\n",
    "        plot.mutation_rate(df=df,\n",
    "                           sample=samp,\n",
    "                           construct=construct,\n",
    "                           plot_type='sequence',\n",
    "                           index='index')\n",
    "        utils.save_fig(path=f\"data/figs/date/{study}/mut_per_base/sequence/{construct}/\", \n",
    "                    title=f\"base_per_base_sequence_{samp}_{construct}\")\n",
    "        plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeltaG plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in study.samples:\n",
    "    plot.deltaG(df=df, sample=samp)\n",
    "\n",
    "    utils.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "             title=f\"deltaG_{samp}\")\n",
    "\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samples correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [constructs[0]]:\n",
    "        df_global_corr = plot.correlation_n_samples(df, study, construct)\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study}\", \n",
    "                      title=f\"correlation_{study}_{construct}\")\n",
    "        plt.title(f\"Study: {study}\")\n",
    "        plt.close(not show_plots)\n",
    "        print(construct, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = False\n",
    "for study in studies:\n",
    "    samples = study['samples']\n",
    "    for constructs in df.construct.unique():\n",
    "        constructs_name = constructs\n",
    "        df_global_corr = plot.correlation_n_samples(df, samples, constructs)\n",
    "        plt.title(f\"Correlation between samples for study: {study}, constructs: {constructs_name}\")\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study}/{constructs_name}\", \n",
    "                        title=f\"correlation_fit_{study}_{constructs_name}\")\n",
    "        plt.close(not show_plots)\n",
    "\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "            plt.title(f\"{plt_type} of the correlation between samples for study: {study}, constructs: {constructs_name}\")\n",
    "            utils.save_fig(path=f\"data/figs/date/correlation/{study}/{constructs_name}\", \n",
    "                            title=f\"correlation_{plt_type}_{study}_{constructs_name}\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", 'r_value').astype(float)\n",
    "df_global_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plt_type in ['r_value', 'slope']:\n",
    "    pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "    f, ax = plt.subplots(figsize=(28, 10))\n",
    "    sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "    plt.title(plt_type)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                    title=f\"correlation_{plt_type}_{study}_all_constructs\")\n",
    "   # plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = True\n",
    "\n",
    "for study in studies:\n",
    "    samples = study['samples']\n",
    "    df_global_corr = plot.correlation_n_samples(df, samples, constructs)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                    title=f\"correlation_{study}_all_constructs\")\n",
    "    plt.close(not show_plots)\n",
    "\n",
    "    if heat_map:\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax, norm=LogNorm())\n",
    "            utils.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                            title=f\"correlation_{plt_type}_{study}_all_constructs\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = 1\n",
    "for study in studies:\n",
    "    samples = studies[study]['samples']\n",
    "    if study == 'all_samples': continue\n",
    "    plot.correlation_n_samples(df, samples, constructs)\n",
    "    plot.save_fig(path=f\"data/figs/date/global_correlation/{study}\", \n",
    "                title=f\"correlation_{study}_all_constructs\")\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature vs reactivity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, study in studies.iterrows():\n",
    "    plot.mut_rate_along_study(df, Study().from_dict(study.to_dict()), figsize=(16,8))\n",
    "    utils.save_fig(path=f\"../data/figs/date/study_behavior\", \n",
    "                title=f\"{study.name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save columns to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.columns_to_csv(df=df,\n",
    "                   samples=samples,\n",
    "                   columns=['sample', 'construct','full_sequence','roi_sequence','mut_bases','info_bases'],\n",
    "                   title=f\"seq_and_reactivity_{study}\",\n",
    "                   path='data/figs/date/{study}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save construct vs deltaG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.deltaG_vs_construct_to_csv(df=df,    \n",
    "                                 title=f\"deltaG_vs_construct.csv\", \n",
    "                                 path = f\"data/figs/date/{study}\", \n",
    "                                 samples=samples)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "181a95673db9352066c6745a8c0d18f5d1810e89c791a79e01a67e30706bff6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

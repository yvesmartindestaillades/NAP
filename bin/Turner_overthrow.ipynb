{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "This template is meant to be a starter for your customized DREEM output data analysis.\n",
    "\n",
    "- To install this library, please check the installation on the [Git repo](https://github.com/yvesmartindestaillades/NAP).\n",
    "- To learn how to use this library, please get through the [tutorial](tutorial.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turner overthrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LogNorm\n",
    "from os.path import exists, dirname\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "from dreem_nap import data_wrangler, data_manip, database, plot, utils, wrapper\n",
    "from dreem_nap.study import Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data wrangling\n",
    "### Step 1.1: Define your study and some basics about your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiated connection to Firebase!\n",
      "Here are the available studies: dict_keys(['180 mM DMS', '3.1 DMS', '3.2 DMS', '60 mM DMS', 'PEG1K', 'PEG3350', 'PEG8K', 'RNA titration', 'TO_DO_2', 'all samples', 'magnesium', 'replicates 1', 'replicates 2', 'salt', 'spermidine', 'spermine', 'temperature'])\n",
      "Here is your study {'name': 'all samples', 'description': 'Simply all of the valid samples', 'samples': ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'E1', 'E2', 'E3', 'E5', 'E6', 'E7', 'E8', 'E9', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6', 'G7', 'G8', 'G9', 'H1', 'H2', 'H3', 'H4', 'H5', 'H6', 'H7', 'H8', 'H9'], 'title': nan, 'conditions': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0]}\n"
     ]
    }
   ],
   "source": [
    "# Set your root folder for the database (at the moment, keep Yves)\n",
    "folder = 'Yves'\n",
    "\n",
    "path_to_data = '../data'\n",
    "\n",
    "# Pull the firebase\n",
    "# Firebase credentials file\n",
    "firebase_credentials_file = f\"{path_to_data}/credentials_firebase.json\"\n",
    "with open(firebase_credentials_file) as file:\n",
    "    firebase_credentials = json.load(file)\n",
    "database.connect(firebase_credentials)\n",
    "\n",
    "# Select your study\n",
    "study_name = 'all samples' \n",
    "\n",
    "## Set your base coverage high-pass filter value\n",
    "min_bases_cov = 1000 \n",
    "\n",
    "# Set the resolution for the plots\n",
    "mpl.rcParams['figure.dpi'] = 600 # the highest the resolution, the slowest the plotting\n",
    "mpl.rcParams[\"figure.figsize\"] = [25,7]\n",
    "#plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# Depending on the study you select, you'll get a series of samples. You can also create new studies using this dictionary.\n",
    "# Here's an example.\n",
    "\n",
    "# Your studies under the shape of a dataframe\n",
    "df_studies = data_wrangler.load_studies( f\"{path_to_data}/samples.csv\")\n",
    "temp = df_studies.to_dict(orient='index')\n",
    "\n",
    "# Your studies under the shape of a dictionary of Study\n",
    "studies = {study: Study().from_dict(temp[study])  for study in temp}\n",
    "print(f\"Here are the available studies: {studies.keys()}\")\n",
    "\n",
    "# Load the study that you want\n",
    "study = studies[study_name]\n",
    "print(f\"Here is your study {study.to_dict()}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Process new pickle files and push them to Firebase\n",
    "- Select which samples you want to push to Firebase.\n",
    "To plot automatically arrays of samples, see [tutorial](tutorial.ipynb), section 3.2.\n",
    "- Process samples and push them to Firebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle files to process and to push to Firebase\n",
    "pickles_list = []# study.samples # Can be samples if you want to process the samples from your study\n",
    "\n",
    "pickles = {pickle:  f\"{path_to_data}/DREEM/{pickle}/mutation_histos.p\" for pickle in pickles_list}\n",
    "\n",
    "# Indicate the location of your RNA structure file\n",
    "RNAstructureFile =  f\"{path_to_data}/RNAstructureFile.csv\"\n",
    "\n",
    "# Default location for your local database (JSON file)\n",
    "json_file =  f\"{path_to_data}/db.json\"\n",
    "\n",
    "# If the user gives some new pickles files, push them to the firebase, then pull the entire firebase\n",
    "if len(pickles):\n",
    "    data_wrangler.push_samples_to_firebase(pickles = pickles,\n",
    "                        RNAstructureFile = RNAstructureFile,\n",
    "                        firebase_credentials = firebase_credentials,\n",
    "                        min_bases_cov = min_bases_cov, \n",
    "                        folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: Pull the data from the Firebase and clean/reformat it.\n",
    "`df` is used for the analysis. Each of the construct have above 1000 reads for each sample in at least one study.     \n",
    "`df_full` is used for quality quality analysis. It has all construct above 1000 valid reads for each sample individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from database\n",
      "A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 B1 B2 B3 B4 B5 B6 B7 B8 B9 B10 C1 C2 C4 C5 C6 C7 C8 C9 D1 D2 D3 D4 D5 D6 D7 D8 D9 E1 E2 E3 E5 E6 E7 E8 E9 F1 F2 F3 F4 F5 F6 F7 F8 F9 G1 G2 G3 G4 G5 G6 G7 G8 G9 H1 H2 H3 H4 H5 H6 H7 H8 H9 Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymdt/anaconda3/lib/python3.9/site-packages/dreem_nap/data_wrangler.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full['samples_covered'].loc[construct[1].index] = construct[1]['full_sequence'].count()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 constructs were dropped because deltaG was 'void'\n",
      "66 constructs have more than 1000 reads for each base of their ROI on each sample\n"
     ]
    }
   ],
   "source": [
    "df_database = database.load(study=study, folder=folder)\n",
    "\n",
    "#data_wrangler.dump_dict_json(JSONFileDict=json_file, df=df_database)\n",
    "#df_database = data_wrangler.json_load(json_file)\n",
    "\n",
    "# Clean and reformat the dataset\n",
    "df, df_full = data_wrangler.clean_dataset(df_database=df_database,\n",
    "                                             study=study)\n",
    "print(f\"{df.groupby('construct')['samples_covered'].count().count()} constructs have more than {min_bases_cov} reads for each base of their ROI on each sample\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data quality analysis\n",
    "\n",
    "It's always hard to realize that you were analysing noise. Here, we'll get through a series a plot to check the data sanity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of samples and constructs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"samples are: {study.samples}\")\n",
    "print(f\"constructs are: {df.construct.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "`data_manip.get_roi_info()` gives information about the Region of Interest (ROI) of a (sample, construct) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = data_manip.rand_sample_construct(df)\n",
    "\n",
    "data_manip.get_roi_info(df=df,\n",
    "                        samp=studies['180 mM DMS'].samples[2],\n",
    "                        construct= 8430,\n",
    "                        bases= ['A', 'C'], #bases you want \n",
    "                        structure='full', # which structure prediction, 'full' or 'roi' \n",
    "                        overlay=(0, 0) # extend/shrink the roi, default is 0\n",
    "                       # roi_index= [80, 110]\n",
    "                        )#.xs((True, '0'),level=('paired','roi_structure_comparison'))    #additional filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "construct = 8430\n",
    "for samp in studies['180 mM DMS'].samples:\n",
    "    wrapper.about_a_sample_construct(df, samp, construct, f\"{path_to_data}/figs/date/about a construct/{construct}/{samp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (sample, construct)-specific base coverage plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp, construct = data_manip.rand_sample_construct(df)\n",
    "plot.base_coverage(df, samp, construct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the base coverage per construct distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.base_coverage_ROI_for_all_constructs(df=df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity-check construct-wise base coverage plots\n",
    "Plot randomly picked sequences to check the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.random_9_base_coverage(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the roi part coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "             column=\"cov_bases_roi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the second half coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap(df = df, \n",
    "                column=\"cov_bases_sec_half\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data analysis\n",
    "In this part, we know that we read good data, and we want to visualize it through different plots.\n",
    "\n",
    "### Analysis parameters\n",
    "\n",
    "Define a limited amount of constructs if that's useful to you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the plots on this notebook? Not recommended if numerous plots\n",
    "show_plots = True\n",
    "\n",
    "# Constructs used\n",
    "a_few_constructs = df.construct.unique()[:3].tolist()\n",
    "first_construct = df.construct.unique()[0].tolist()\n",
    "constructs_per_name = {\n",
    "    'all_construct': df.construct.unique().tolist(),\n",
    "    str(a_few_constructs) : a_few_constructs,\n",
    "    str(first_construct): [first_construct]\n",
    "}\n",
    "\n",
    "# Select constructs here\n",
    "constructs_name = str(a_few_constructs)\n",
    "\n",
    "# Define what you will analyse\n",
    "constructs = constructs_per_name[constructs_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of mutation (sample-construct)\n",
    "\n",
    "`plot.mut_histogam(df, sample, construct, plot_type, index, normalize)` plots the mutation rate base-wise for a given construct of a given sample as a barplot. \n",
    "Arguments:\n",
    "- `plot_type` :\n",
    "    - `'sequence'` : each bar is colored w.r.t to the base of the original sequence.\n",
    "    - `'partition'` : each bar shows the partition of into which bases this base mutates.\n",
    "- `index`:\n",
    "    - `'index'`: each base is identified with its position number\n",
    "    - `'base'`: each base is identified with its type (A, C, G, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructs = constructs # Define this beforehand\n",
    "\n",
    "for construct in constructs:\n",
    "    for samp in study.samples:\n",
    "        plot.mut_histogram(df=df,\n",
    "                           samp=samp,\n",
    "                           construct=construct,\n",
    "                           plot_type='index') # Sequence (show the base and their index) or partition (show what the base mutates to)\n",
    "        utils.save_fig(path=f\"data/figs/date/{study.name}/mut_per_base/sequence/{construct}/\", \n",
    "                    title=f\"base_per_base_sequence_{samp}_{construct}\")\n",
    "        plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeltaG plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samp in study.samples:\n",
    "    plot.deltaG(df=df, sample=samp)\n",
    "\n",
    "    utils.save_fig(path=f\"data/figs/date/{study}/deltaG/\", \n",
    "             title=f\"deltaG_{samp}\")\n",
    "\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples correlation\n",
    "Only plot the correlation construct-by-construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [constructs[0]]:\n",
    "        df_global_corr = plot.correlation_n_samples(df, study, [construct])\n",
    "        plt.title(f\"Study: {study.name}\")\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study.name}\", \n",
    "                      title=f\"correlation_{study.name}_{construct}\")\n",
    "        plt.close(not show_plots)\n",
    "        print(construct, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap of the R value + heatmap of the slope for the previous correlation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plt_type in ['r_value', 'slope']:\n",
    "    pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "    f, ax = plt.subplots(figsize=(28, 10))\n",
    "    sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "    plt.title(plt_type)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study.name}\", \n",
    "                    title=f\"correlation_{plt_type}_{study.name}_all_constructs\")\n",
    "    plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the correlation + heatmap of the R value + heatmap of the slope construct by construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots = False\n",
    "for _, study in studies:\n",
    "    samples = study.samples\n",
    "    for construct in df.construct.unique():\n",
    "        construct_name = construct\n",
    "        df_global_corr = plot.correlation_n_samples(df, study, construct)\n",
    "        plt.title(f\"Correlation between samples for study: {study.name}, constructs: {construct_name}\")\n",
    "        utils.save_fig(path=f\"data/figs/date/correlation/{study.name}/{construct_name}\", \n",
    "                        title=f\"correlation_fit_{study.name}_{construct_name}\")\n",
    "        plt.close(not show_plots)\n",
    "\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax)#, norm=LinNorm())\n",
    "            plt.title(f\"{plt_type} of the correlation between samples for study: {study.name}, construct: {construct_name}\")\n",
    "            utils.save_fig(path=f\"data/figs/date/correlation/{study.name}/{construct_name}\", \n",
    "                            title=f\"correlation_{plt_type}_{study.name}_{construct_name}\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the correlation + heatmap of the R value + heatmap of the slope for a bunch of constructs altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map = True\n",
    "\n",
    "constructs = constructs # this has to be defined somewhere\n",
    "\n",
    "for _, study in studies.iterrows():\n",
    "    df_global_corr = plot.correlation_n_samples(df, study, constructs)\n",
    "    utils.save_fig(path=f\"data/figs/date/global_correlation/{study.name}\", \n",
    "                    title=f\"correlation_{study.name}_all_constructs\")\n",
    "    plt.close(not show_plots)\n",
    "\n",
    "    if heat_map:\n",
    "        for plt_type in ['r_value', 'slope']:\n",
    "            pivot = df_global_corr.pivot(\"sample_0\",\"sample_1\", plt_type).astype(float)\n",
    "            f, ax = plt.subplots(figsize=(28, 10))\n",
    "            sns.heatmap(pivot, annot=False, linewidths=0, ax=ax, norm=LogNorm())\n",
    "            utils.save_fig(path=f\"data/figs/date/global_correlation/{study.name}\", \n",
    "                            title=f\"correlation_{plt_type}_{study.name}_all_constructs\")\n",
    "            plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature vs reactivity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.study_sample(df, study, scale_x='log',structure='full', overlay=5, figsize=(16,8))\n",
    "utils.save_fig(path=f\"{path_to_data}/figs/date/study_behavior\", \n",
    "            title=f\"{study.name}.png\")\n",
    "plt.close(not show_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _, study in studies.iterrows():\n",
    "    study =  Study().from_dict(study.to_dict())\n",
    "    study.models = ['lambda x,a: np.log(x)+a']\n",
    "    plot.study_sample(df, study, scale_x='log',structure='full', overlay=5, figsize=(16,8))\n",
    "    utils.save_fig(path=f\"{path_to_data}/figs/date/study_behavior\", \n",
    "                title=f\"{study.name}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-wise mutation along a study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in [df.construct.unique()[0]]:\n",
    "    for stu in studies.iterrows():\n",
    "        study=Study().from_dict(stu[1].to_dict())\n",
    "        if study.name == 'all samples':\n",
    "            continue\n",
    "        plot.study_base(df=df,\n",
    "                study=Study().from_dict(studies.loc['temperature']),\n",
    "                construct=9572, \n",
    "                scale_x='log', # can be log or lin\n",
    "                bases=['A','C'],  # bsaes you want in A, C, G, T\n",
    "                structure='full', # sequence for structure prediction. full or roi. \n",
    "                #overlay = 10,  # expand/shrink the roi. Can't expand roi if structure = 'roi'\n",
    "                base_index=list(range(40,120))) # select your favorite bases. Can't expand roi if structure = 'roi' \n",
    "                \n",
    "        utils.save_fig(path= f\"{path_to_data}/figs/date/Base-wise mutation along a study/{study.name}\", \n",
    "                       title=f\"{construct}_{study.name}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save columns to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manip.columns_to_csv(df=df,\n",
    "                   samples=samples,\n",
    "                   columns=['sample', 'construct','full_sequence','roi_sequence','mut_bases','info_bases'],\n",
    "                   title=f\"seq_and_reactivity_{study}\",\n",
    "                   path='data/figs/date/{study}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save construct vs deltaG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manip.deltaG_vs_construct_to_csv(df=df,    \n",
    "                                 title=f\"deltaG_vs_construct.csv\", \n",
    "                                 path = f\"data/figs/date/{study}\", \n",
    "                                 samples=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "181a95673db9352066c6745a8c0d18f5d1810e89c791a79e01a67e30706bff6f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
